{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b214a3d4",
   "metadata": {},
   "source": [
    "ver 1:\n",
    "simple CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af0c12e",
   "metadata": {},
   "source": [
    "# Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2500151a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:08:59.606381Z",
     "start_time": "2023-11-15T15:08:58.971057Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4b6fb6",
   "metadata": {},
   "source": [
    "# CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4df9fa75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:08:59.609201Z",
     "start_time": "2023-11-15T15:08:59.607462Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68a5bd4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:08:59.613200Z",
     "start_time": "2023-11-15T15:08:59.610317Z"
    }
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    batch = 128\n",
    "    shuffle = True\n",
    "    num_classes = 10\n",
    "    learning_rate = 0.0001\n",
    "    epoch = 20\n",
    "\n",
    "    H = 28\n",
    "    W = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65be6713",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f1feaf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:00.409073Z",
     "start_time": "2023-11-15T15:08:59.613860Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the dataset using NumPy\n",
    "# Load train data\n",
    "train_data = np.loadtxt('train.csv', delimiter=',', skiprows=1)\n",
    "train_labels = train_data[:, 0]  # Labels 0 and 1\n",
    "train_data = train_data[:, 1:]   # Pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7b3898",
   "metadata": {},
   "source": [
    "## Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14c4c0e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:00.413868Z",
     "start_time": "2023-11-15T15:09:00.410235Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., ..., 7., 6., 9.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4182934",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:00.418528Z",
     "start_time": "2023-11-15T15:09:00.414476Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_labels) # from 0 to 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "110f9876",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:00.421423Z",
     "start_time": "2023-11-15T15:09:00.419337Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee60447",
   "metadata": {},
   "source": [
    "## Plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9e54e1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:00.488315Z",
     "start_time": "2023-11-15T15:09:00.422170Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = np.reshape(train_data, (train_data.shape[0],28,28,1)).copy()/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e718eca9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:00.491564Z",
     "start_time": "2023-11-15T15:09:00.489362Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 28, 28, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc11b338",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:00.556067Z",
     "start_time": "2023-11-15T15:09:00.492163Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f55facb08e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1843b1ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:00.558755Z",
     "start_time": "2023-11-15T15:09:00.556794Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = np.einsum('bhwc ->bchw',train_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00910067",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:00.563194Z",
     "start_time": "2023-11-15T15:09:00.561446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 1, 28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "931702c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:00.566467Z",
     "start_time": "2023-11-15T15:09:00.563817Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class CustomDataLoader:\n",
    "    def __init__(self, data, targets, batch_size, shuffle=True, drop_last=False):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.drop_last = drop_last\n",
    "        self.num_samples = len(self.data)\n",
    "        self.indices = np.arange(self.num_samples)\n",
    "        \n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for start_idx in range(0, self.num_samples, self.batch_size):\n",
    "            end_idx = start_idx + self.batch_size\n",
    "            if self.drop_last and end_idx > self.num_samples:\n",
    "                continue\n",
    "\n",
    "            batch_indices = self.indices[start_idx:end_idx]\n",
    "            batch_data = self.data[batch_indices]\n",
    "            batch_targets = self.targets[batch_indices]\n",
    "            \n",
    "            yield batch_data, batch_targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.drop_last:\n",
    "            return self.num_samples // self.batch_size\n",
    "        else:\n",
    "            return (self.num_samples + self.batch_size - 1) // self.batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e96ad079",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:00.611914Z",
     "start_time": "2023-11-15T15:09:00.567087Z"
    }
   },
   "outputs": [],
   "source": [
    "trainloader = CustomDataLoader(train_data[:10000].copy(), train_labels[:10000].copy(), CFG.batch, shuffle=CFG.shuffle, drop_last =True)\n",
    "testloader = CustomDataLoader(train_data[10001:].copy(), train_labels[10001:].copy(), CFG.batch, shuffle=CFG.shuffle, drop_last =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc169d5",
   "metadata": {},
   "source": [
    "# Linaer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eace8543",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:00.615662Z",
     "start_time": "2023-11-15T15:09:00.612800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define Linear layer class\n",
    "class Linear:\n",
    "    def __init__(self, in_features, out_features):\n",
    "#         self.W = np.random.randn(in_features, out_features) * 0.01  # Initialize weights\n",
    "        self.W = np.random.randn(in_features, out_features) \n",
    "        self.b = np.random.randn(out_features)  # Initialize bias\n",
    "        self.gradW = np.zeros_like(self.W)  # Gradient of the layer weights\n",
    "        self.gradB = np.zeros_like(self.b)  # Gradient of the layer bias\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.input = x  # Store input for backpropagation\n",
    "        return np.dot(x, self.W) + self.b\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        self.gradW = np.dot(self.input.T, grad_output)\n",
    "        self.gradB = np.sum(grad_output, axis=0)\n",
    "        return np.dot(grad_output, self.W.T)  # Gradient for the previous layer\n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "# Define ReLU activation class\n",
    "class ReLU:\n",
    "    def forward(self, x):\n",
    "        self.input = x  # Store input for backpropagation\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        return grad_output * (self.input > 0)\n",
    "    \n",
    "    def __call__(self,x):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8d667a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:00.620341Z",
     "start_time": "2023-11-15T15:09:00.616561Z"
    }
   },
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def __init__(self):\n",
    "        self.output = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Compute the exponential terms in a stable way.\n",
    "        x_exp = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        \n",
    "        # Compute the softmax output\n",
    "        self.output = x_exp / np.sum(x_exp, axis=1, keepdims=True)\n",
    "        \n",
    "        return self.output\n",
    "\n",
    "    def backward(self, d_output):\n",
    "        # Using broadcasting and vectorization to compute d_input in one shot\n",
    "        output_expanded = np.expand_dims(self.output, axis=2)  # Expand output dims for broadcasting\n",
    "        d_output_expanded = np.expand_dims(d_output, axis=2)  # Expand d_output dims for broadcasting\n",
    "\n",
    "        jacobian_matrix = np.eye(self.output.shape[1]) - output_expanded * np.swapaxes(output_expanded, 1, 2)\n",
    "        d_input = np.einsum('ijk,ikj->ik', jacobian_matrix, d_output_expanded).squeeze()\n",
    "\n",
    "        return d_input\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "class CrossEntropyLoss:\n",
    "    def __init__(self):\n",
    "        self.softmax = Softmax()\n",
    "        self.logits = None\n",
    "        self.labels = None\n",
    "        self.epsilon = 1e-18  # Adding epsilon for numerical stability\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        # Apply Softmax to logits and clip values\n",
    "        probs = logits.clip(min=self.epsilon,max=None)\n",
    "        probs = self.softmax.forward(probs)\n",
    "        # Add a small constant to avoid log(0)\n",
    "        \n",
    "        log_probs = np.log(probs)\n",
    "\n",
    "        # Calculate the loss\n",
    "        self.logits = logits\n",
    "        self.labels = labels\n",
    "        n_samples = logits.shape[0]\n",
    "        log_likelihood = -np.sum(labels * log_probs)  # Using log_probs\n",
    "        loss = log_likelihood / n_samples\n",
    "    \n",
    "        return loss\n",
    "\n",
    "\n",
    "    def backward(self):\n",
    "        n_samples = self.logits.shape[0]\n",
    "        \n",
    "        # Direct gradient for cross-entropy loss with softmax is just the difference\n",
    "        # between the predicted probabilities and the actual one-hot encoded labels\n",
    "        d_logits = self.softmax.output - self.labels\n",
    "        d_logits /= n_samples\n",
    "        \n",
    "        return d_logits\n",
    "\n",
    "    def __call__(self, y_pred, y_true):\n",
    "        return self.forward(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63e523b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:00.624482Z",
     "start_time": "2023-11-15T15:09:00.621223Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# #working\n",
    "# class Conv2d:\n",
    "#     def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "#         self.kernel_size = kernel_size\n",
    "#         self.stride = stride\n",
    "#         self.padding = padding\n",
    "#         self.W = np.random.randn(out_channels, in_channels, kernel_size, kernel_size)\n",
    "#         self.b = np.zeros((out_channels,))\n",
    "\n",
    "#         self.gradW = np.zeros_like(self.W)\n",
    "#         self.gradB = np.zeros_like(self.b)\n",
    "#         self.cache = None\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         batch_size, in_channels, in_height, in_width = x.shape\n",
    "#         out_channels = self.W.shape[0]\n",
    "\n",
    "#         out_height = (in_height - self.kernel_size + 2 * self.padding) // self.stride + 1\n",
    "#         out_width = (in_width - self.kernel_size + 2 * self.padding) // self.stride + 1\n",
    "\n",
    "#         if self.padding > 0:\n",
    "#             x = np.pad(x, ((0, 0), (0, 0), (self.padding, self.padding), (self.padding, self.padding)), 'constant')\n",
    "\n",
    "#         self.cache = x\n",
    "\n",
    "#         # Initialize output tensor\n",
    "#         output = np.zeros((batch_size, out_channels, out_height, out_width))\n",
    "\n",
    "#         # Using np.einsum to handle the convolution\n",
    "#         for i in range(0, in_height - self.kernel_size + 1, self.stride):\n",
    "#             for j in range(0, in_width - self.kernel_size + 1, self.stride):\n",
    "#                 x_slice = x[:, :, i:i + self.kernel_size, j:j + self.kernel_size]\n",
    "#                 output[:, :, i // self.stride, j // self.stride] = np.einsum('ijkl, ojkl -> io', x_slice, self.W) + self.b\n",
    "\n",
    "#         return np.real(output)\n",
    "\n",
    "#     def backward(self, grad_output):\n",
    "#         x = self.cache\n",
    "#         batch_size, out_channels, _, _ = grad_output.shape\n",
    "\n",
    "#         grad_input = np.zeros_like(x)\n",
    "#         self.gradW = np.zeros_like(self.W)\n",
    "#         self.gradB = np.zeros_like(self.b)\n",
    "\n",
    "#         for i in range(0, grad_input.shape[2] - self.kernel_size + 1, self.stride):\n",
    "#             for j in range(0, grad_input.shape[3] - self.kernel_size + 1, self.stride):\n",
    "#                 x_slice = x[:, :, i:i + self.kernel_size, j:j + self.kernel_size]\n",
    "#                 grad_output_slice = grad_output[:, :, i // self.stride, j // self.stride]\n",
    "\n",
    "#                 # Update gradient of input using einsum\n",
    "#                 grad_input[:, :, i:i + self.kernel_size, j:j + self.kernel_size] += np.einsum('io, ojkl -> ijkl', grad_output_slice, self.W)\n",
    "                \n",
    "#                 # Update gradient of weights using einsum\n",
    "#                 self.gradW += np.einsum('io, ijkl -> ojkl', grad_output_slice, x_slice)\n",
    "\n",
    "#                 # Update gradient of bias\n",
    "#                 self.gradB += np.sum(grad_output_slice, axis=0)\n",
    "#         return np.real(grad_input)\n",
    "\n",
    "#     def __call__(self, x):\n",
    "#         return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1dbefc2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:00.628517Z",
     "start_time": "2023-11-15T15:09:00.625407Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.fft import fft2, ifft2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbb11c1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:00.631760Z",
     "start_time": "2023-11-15T15:09:00.629464Z"
    }
   },
   "outputs": [],
   "source": [
    "# kernel_size = 3\n",
    "# stride = 1\n",
    "# padding = 0\n",
    "# out_channels = 5\n",
    "# in_channels = 5\n",
    "# W = np.random.randn(out_channels, in_channels, kernel_size, kernel_size)\n",
    "# b = np.zeros(out_channels)\n",
    "# cache = None\n",
    "\n",
    "# x = np.random.randn(64, 1, 28, 28)\n",
    "# batch_size, in_channels, in_height, in_width = x.shape\n",
    "\n",
    "# out_channels = W.shape[0]\n",
    "\n",
    "# out_height = (in_height - kernel_size + 2 * padding) // stride + 1\n",
    "# out_width = (in_width - kernel_size + 2 * padding) // stride + 1\n",
    "\n",
    "# if padding > 0:\n",
    "#     x = np.pad(x, ((0, 0), (0, 0), (padding, padding), (padding, padding)), 'constant')\n",
    "\n",
    "# output = np.zeros((batch_size, out_channels, out_height, out_width))\n",
    "\n",
    "# x = fft2(x, axes=(2, 3))\n",
    "# x = np.real(x)\n",
    "# for i in range(0, in_height - kernel_size + 1, stride):\n",
    "#             for j in range(0, in_width - kernel_size + 1, stride):\n",
    "#                 x_slice = x[:, :, i:i + kernel_size, j:j + kernel_size]\n",
    "#                 output[:, :, i // stride, j // stride] = np.einsum('ijkl, ojkl -> io', x_slice, W) + b\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e563b327",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:00.634964Z",
     "start_time": "2023-11-15T15:09:00.632460Z"
    }
   },
   "outputs": [],
   "source": [
    "# output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0b2922d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:00.648842Z",
     "start_time": "2023-11-15T15:09:00.635645Z"
    }
   },
   "outputs": [],
   "source": [
    "# x_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03dd01f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:00.653368Z",
     "start_time": "2023-11-15T15:09:00.649571Z"
    }
   },
   "outputs": [],
   "source": [
    "# output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b9149cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:00.657772Z",
     "start_time": "2023-11-15T15:09:00.654096Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# x_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37091bd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:00.678389Z",
     "start_time": "2023-11-15T15:09:00.658486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass, output shape: (10, 6, 30, 30)\n",
      "Backward pass, dx shape: (10, 6, 30, 30)\n"
     ]
    }
   ],
   "source": [
    "from numpy.fft import fft2, ifft2\n",
    "import numpy as np\n",
    "\n",
    "class Conv2d:\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding=0, stride=1):\n",
    "        self.W = np.random.randn(out_channels, in_channels, kernel_size, kernel_size)\n",
    "        self.b = np.zeros(out_channels)\n",
    "        self.gradW = np.zeros_like(self.W)\n",
    "        self.gradB = np.zeros_like(self.b)\n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        H_out = (H - self.W.shape[2] + 2*self.padding) // self.stride + 1\n",
    "        W_out = (W - self.W.shape[3] + 2*self.padding) // self.stride + 1\n",
    "        out = np.zeros((N, self.W.shape[0], H_out, W_out))\n",
    "        \n",
    "        for n in range(N):\n",
    "            for m in range(self.W.shape[0]):\n",
    "                fft_x = fft2(x[n], (H_out, W_out), axes=[-2, -1])\n",
    "                fft_w = fft2(self.W[m], (H_out, W_out), axes=[-2, -1])\n",
    "                conv_freq = fft_x * fft_w\n",
    "                conv_spatial = np.real(ifft2(conv_freq, axes=[-2, -1]))\n",
    "                out[n, m] = conv_spatial.sum(axis=0) + self.b[m]\n",
    "                \n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        N, F, H_out, W_out = dout.shape\n",
    "        C = self.W.shape[1]\n",
    "        \n",
    "        self.gradB = np.sum(dout, axis=(0, 2, 3))\n",
    "        self.gradW = np.zeros_like(self.W)\n",
    "        dx = np.zeros((N, F, H_out, W_out))\n",
    "        \n",
    "        for n in range(N):\n",
    "            for f in range(F):\n",
    "                fft_dout = fft2(dout[n, f], axes=[-2, -1])\n",
    "                \n",
    "                for c in range(C):\n",
    "                    fft_w = fft2(self.W[f, c], (H_out, W_out), axes=[-2, -1])  # Match the shape\n",
    "                    \n",
    "                    fft_dx = fft_dout * fft_w\n",
    "                    dx_spatial = np.real(ifft2(fft_dx, axes=[-2, -1]))\n",
    "                    dx[n, c] += dx_spatial\n",
    "                    \n",
    "                    fft_x = fft2(dx_spatial, axes=[-2, -1])  # Use already calculated dx_spatial for calculating dW\n",
    "                    fft_dW = fft_dout * fft_x\n",
    "                    dW_spatial = np.real(ifft2(fft_dW, axes=[-2, -1]))\n",
    "                    \n",
    "                    self.gradW[f, c] += dW_spatial[:self.W.shape[2], :self.W.shape[3]]\n",
    "        \n",
    "        return dx\n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "# Example usage\n",
    "conv = Conv2d(3, 6, 3, padding=0)\n",
    "input_data = np.random.randn(10, 3, 32, 32)\n",
    "output = conv.forward(input_data)\n",
    "print(\"Forward pass, output shape:\", output.shape)\n",
    "\n",
    "dout = np.random.randn(*output.shape)\n",
    "\n",
    "dx = conv.backward(dout)\n",
    "print(\"Backward pass, dx shape:\", dx.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba44aea4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:00.680552Z",
     "start_time": "2023-11-15T15:09:00.679165Z"
    }
   },
   "outputs": [],
   "source": [
    "# out_H = (input_data[0] - kernel_size +2*1)//stride + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7792818",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:00.683913Z",
     "start_time": "2023-11-15T15:09:00.681332Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def mean(x):\n",
    "    return np.sum(x)/x.size\n",
    "def var(x):\n",
    "    return mean(np.square(x-mean(x)))\n",
    "def std(x):\n",
    "    return np.sqrt(var(x))\n",
    "def median(x):\n",
    "    sorted_x = np.sort(x)  # Sort the array in ascending order\n",
    "    n = x.size  # Get the size of the array\n",
    "    \n",
    "    if n % 2 == 1:  # If the size is odd\n",
    "        return sorted_x[n // 2]  # Return the middle element\n",
    "    else:  # If the size is even\n",
    "        m1 = sorted_x[n // 2 - 1]  # Get the first middle element\n",
    "        m2 = sorted_x[n // 2]  # Get the second middle element\n",
    "        return (m1 + m2) / 2  # Return the average of the two middle elements\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "646af5eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:00.687055Z",
     "start_time": "2023-11-15T15:09:00.684688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5 8.25 2.8722813232690143 4.5\n"
     ]
    }
   ],
   "source": [
    "arr = [0,1,2,3,4,5,6,7,8,9]\n",
    "arr = np.array(arr)\n",
    "print(mean(arr), var(arr), std(arr), median(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "677e8b58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:00.692205Z",
     "start_time": "2023-11-15T15:09:00.687676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: (2, 3, 4, 4)\n",
      "Output: (2, 3, 2, 2)\n",
      "Output gradient: (2, 3, 2, 2)\n",
      "Input gradient: (2, 3, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MaxPool2d:\n",
    "    def __init__(self, kernel_size):\n",
    "        self.kernel_size = kernel_size  # Define the kernel size for max pooling\n",
    "        self.cache = {}  # Cache to store intermediate values for backward computation\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Get the shape of input tensor\n",
    "        N, C, H, W = x.shape\n",
    "        \n",
    "        # Compute the dimensions of the output after max pooling\n",
    "        H_out = H // self.kernel_size\n",
    "        W_out = W // self.kernel_size\n",
    "        \n",
    "        # Initialize output tensor\n",
    "        out = np.zeros((N, C, H_out, W_out))\n",
    "        \n",
    "        # Store the indices where max values are found\n",
    "        self.cache['max_indices'] = np.zeros((N, C, H_out, W_out), dtype=int)\n",
    "        \n",
    "        # Perform max pooling\n",
    "        for i in range(H_out):\n",
    "            for j in range(W_out):\n",
    "                # Extract each patch\n",
    "                patch = x[:, :, i*self.kernel_size:(i+1)*self.kernel_size, j*self.kernel_size:(j+1)*self.kernel_size]\n",
    "                \n",
    "                # Find the maximum value in each patch and its index\n",
    "                out[:, :, i, j] = np.max(patch, axis=(2, 3))\n",
    "                self.cache['max_indices'][:, :, i, j] = np.argmax(patch.reshape(N, C, -1), axis=2)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, d_out):\n",
    "        # Retrieve cached values\n",
    "        max_indices = self.cache['max_indices']\n",
    "        \n",
    "        # Get the shape of the output gradient tensor\n",
    "        N, C, H_out, W_out = d_out.shape\n",
    "        \n",
    "        # Initialize the input gradient tensor\n",
    "        d_x = np.zeros((N, C, H_out * self.kernel_size, W_out * self.kernel_size))\n",
    "        \n",
    "        # Perform backward pass to propagate the gradients\n",
    "        for i in range(H_out):\n",
    "            for j in range(W_out):\n",
    "                # Initialize a zero patch for each input patch\n",
    "                d_patch = np.zeros((N, C, self.kernel_size, self.kernel_size))\n",
    "                \n",
    "                # Get the indices where max values are found in the forward pass\n",
    "                indices = max_indices[:, :, i, j]\n",
    "                \n",
    "                # Update the patch with corresponding gradients\n",
    "                d_patch.reshape(N, C, -1)[np.arange(N)[:, None], np.arange(C), indices] = d_out[:, :, i, j]\n",
    "                \n",
    "                # Place the computed gradient patch back into the gradient tensor\n",
    "                d_x[:, :, i*self.kernel_size:(i+1)*self.kernel_size, j*self.kernel_size:(j+1)*self.kernel_size] = d_patch\n",
    "        \n",
    "        return d_x\n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "# Test the MaxPool2d class\n",
    "x = np.random.randn(2, 3, 4, 4)  # Random tensor with shape (batch_size, channels, height, width)\n",
    "max_pool = MaxPool2d(2)\n",
    "out = max_pool.forward(x)\n",
    "d_out = np.random.randn(*out.shape)\n",
    "d_x = max_pool.backward(d_out)\n",
    "\n",
    "print(\"Input:\", x.shape)\n",
    "print(\"Output:\", out.shape)\n",
    "print(\"Output gradient:\", d_out.shape)\n",
    "print(\"Input gradient:\", d_x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9652e2e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:00.695870Z",
     "start_time": "2023-11-15T15:09:00.692871Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# class MaxPool2d:\n",
    "#     def __init__(self, kernel_size):\n",
    "#         self.kernel_size = kernel_size\n",
    "#         self.cache = None  # To store forward-pass data needed for backpropagation\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         N, C, H, W = x.shape\n",
    "#         H_out = H // self.kernel_size\n",
    "#         W_out = W // self.kernel_size\n",
    "\n",
    "#         # Reshape for max pooling\n",
    "#         x_reshaped = x.reshape(N, C, H_out, self.kernel_size, W_out, self.kernel_size)\n",
    "\n",
    "#         # Perform max pooling\n",
    "#         out = x_reshaped.max(axis=(3, 5))\n",
    "\n",
    "#         # Store indices of max values\n",
    "#         self.cache = np.zeros((N, C, H_out, W_out), dtype=int)\n",
    "#         for i in range(self.kernel_size):\n",
    "#             for j in range(self.kernel_size):\n",
    "#                 mask = (x_reshaped[:,:, :, i, :, j] == out)\n",
    "#                 self.cache = np.logical_or(self.cache, mask)\n",
    "\n",
    "#         return out\n",
    "\n",
    "# #     def backward(self, grad_output):\n",
    "# #         N, C, H_out, W_out = grad_output.shape\n",
    "\n",
    "# #         # Initialize grad_input to zeros\n",
    "# #         grad_input = np.zeros((N, C, H_out * self.kernel_size, W_out * self.kernel_size), dtype=grad_output.dtype)\n",
    "\n",
    "# #         # Scatter gradient to the positions of max values\n",
    "# #         for i in range(self.kernel_size):\n",
    "# #             for j in range(self.kernel_size):\n",
    "# #                 grad_input[:,:, i::self.kernel_size, j::self.kernel_size] += self.cache * grad_output\n",
    "\n",
    "# #         return grad_input\n",
    "#     def backward(self, grad_output):\n",
    "#         print(f\"Shape of grad_output at beginning of maxpool backward: {grad_output.shape}\")\n",
    "#         N, C, H_out, W_out = grad_output.shape\n",
    "        \n",
    "#         # Initialize grad_input\n",
    "#         grad_input = np.zeros((N, C, H_out * self.kernel_size, W_out * self.kernel_size), dtype=grad_output.dtype)\n",
    "#         print('grand_input shape',grad_input.shape)\n",
    "# #         for i in range(self.kernel_size):\n",
    "# #             for j in range(self.kernel_size):\n",
    "                \n",
    "# #                 print(f\"Shape of mask: {mask.shape}\")\n",
    "# #                 mask_broad = np.broadcast_to(mask, grad_input[:, :, i::self.kernel_size, j::self.kernel_size].shape)\n",
    "# #                 grad_output_broad = np.broadcast_to(grad_output[:, :, i//self.kernel_size, j//self.kernel_size], grad_input[:, :, i::self.kernel_size, j::self.kernel_size].shape)\n",
    "\n",
    "# #                 grad_input[:, :, i::self.kernel_size, j::self.kernel_size] += mask_broad * grad_output_broad\n",
    "# #         for n in range(N):\n",
    "#         # Warning: This is computationally inefficient\n",
    "#         for n in range(N):\n",
    "#             for c in range(C):\n",
    "#                 for h in range(0, H_out, self.kernel_size):\n",
    "#                     for w in range(0, W_out, self.kernel_size):\n",
    "#                         mask = self.cache[:, :, i::self.kernel_size, j::self.kernel_size]\n",
    "#                         grad_input[n, c, h:h+self.kernel_size, w:w+self.kernel_size] += mask[n, c, h//self.kernel_size, w//self.kernel_size] * grad_output[n, c, h//self.kernel_size, w//self.kernel_size]\n",
    "        \n",
    "#         print(f\"Shape of grad_input at end of maxpool backward: {grad_input.shape}\")\n",
    "#         return grad_input\n",
    "\n",
    "#     def __call__(self, x):\n",
    "#         return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "910c56bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:00.699321Z",
     "start_time": "2023-11-15T15:09:00.696425Z"
    }
   },
   "outputs": [],
   "source": [
    "X,y = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61e412f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:00.702118Z",
     "start_time": "2023-11-15T15:09:00.699893Z"
    }
   },
   "outputs": [],
   "source": [
    "maxpool = MaxPool2d(kernel_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c323d40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:00.704965Z",
     "start_time": "2023-11-15T15:09:00.702656Z"
    }
   },
   "outputs": [],
   "source": [
    "maxpool1 = MaxPool2d(kernel_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "336d8b26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:00.787794Z",
     "start_time": "2023-11-15T15:09:00.705618Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 16, 26, 26)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=0, stride=1)\n",
    "\n",
    "conv(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74004dad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:01.318979Z",
     "start_time": "2023-11-15T15:09:00.788499Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 16, 8, 8)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxpool1(conv(conv(maxpool(conv(conv(X)))))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c8a5852",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:01.421897Z",
     "start_time": "2023-11-15T15:09:01.319863Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 16, 13, 13)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxpool(conv(X)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c4837167",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:01.425045Z",
     "start_time": "2023-11-15T15:09:01.422876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_size = 3\n",
    "padding = 0\n",
    "stride= 1\n",
    "out_H = (CFG.H - kernel_size +2*padding) //stride+1\n",
    "out_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d50c7c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:01.429409Z",
     "start_time": "2023-11-15T15:09:01.425698Z"
    }
   },
   "outputs": [],
   "source": [
    "kernel_size = 2\n",
    "out_H = out_H // kernel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "31a5ba01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:01.432978Z",
     "start_time": "2023-11-15T15:09:01.430192Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "557ef675",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:01.440865Z",
     "start_time": "2023-11-15T15:09:01.437472Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_size=3\n",
    "out_H = (out_H- kernel_size +2*padding) //stride+1\n",
    "out_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69cf3a20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:01.443791Z",
     "start_time": "2023-11-15T15:09:01.442101Z"
    }
   },
   "outputs": [],
   "source": [
    "#MaxPool2d shape\n",
    "kernel_size = 2\n",
    "out_H = 5 // kernel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f2ee11fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:01.447134Z",
     "start_time": "2023-11-15T15:09:01.444898Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b09c05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1446696f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:01.452225Z",
     "start_time": "2023-11-15T15:09:01.447701Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "class SimpleCNN:\n",
    "    def __init__(self, out_dim):\n",
    "        # 64,1,26,26\n",
    "        self.conv1 = Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=0, stride=1)\n",
    "        # 64,1,24,24\n",
    "#         self.conv2 = Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=0, stride=1)\n",
    "        # 64,1,12,12\n",
    "        self.relu1 = ReLU()\n",
    "        self.maxpool1 = MaxPool2d(kernel_size = 2)\n",
    "        \n",
    "        # 64,1,10,10\n",
    "#         self.conv3 = Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=0, stride=1)\n",
    "#         # 64,1,5,5\n",
    "#         self.conv4 = Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=0, stride=1)\n",
    "#         # 64,1,2,2\n",
    "#         self.maxpool2 = MaxPool2d(kernel_size = 1)\n",
    "        \n",
    "        self.fc1 = Linear(in_features = 16 * 13*13, out_features = 64)\n",
    "        self.relu2 = ReLU()\n",
    "        self.fc2 = Linear(in_features=64, out_features=64)\n",
    "        self.relu3 = ReLU()\n",
    "        self.fc3 = Linear(in_features=64, out_features=out_dim)\n",
    "        self.relu4 = ReLU()\n",
    "        self.soft = Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "#         print(x)\n",
    "#         print(x.shape)\n",
    "#         x = self.conv2(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "#         x = self.conv3(x)\n",
    "#         x = self.conv4(x)  \n",
    "#         x = self.maxpool2(x)\n",
    "#         print(x.shape)\n",
    "        x = x.reshape(-1, 16 * 13*13)\n",
    "#         print(x.shape)\n",
    "        x = self.relu2(self.fc1(x))\n",
    "        x = self.relu3(self.fc2(x))\n",
    "        x = self.relu4(self.fc3(x))\n",
    "#         print(x.shape)\n",
    "        x = self.soft(x)\n",
    "        return x\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        grad_output = self.soft.backward(grad_output)\n",
    "        grad_output = self.relu4.backward(grad_output)\n",
    "        grad_output = self.fc3.backward(grad_output)\n",
    "        grad_output = self.relu3.backward(grad_output)\n",
    "        grad_output = self.fc2.backward(grad_output)\n",
    "        grad_output = self.relu2.backward(grad_output)\n",
    "        grad_output = self.fc1.backward(grad_output)\n",
    "        grad_output = grad_output.reshape(-1, 16,  13,13)\n",
    "#         print(grad_output.shape)\n",
    "#         grad_output = self.maxpool2.backward(grad_output)\n",
    "#         print(grad_output.shape)\n",
    "#         grad_output = self.conv4.backward(grad_output)\n",
    "#         grad_output = self.conv3.backward(grad_output)\n",
    "        grad_output = self.maxpool1.backward(grad_output)\n",
    "        grad_output = self.relu1.backward(grad_output)\n",
    "#         grad_output = self.conv2.backward(grad_output)\n",
    "        grad_output = self.conv1.backward(grad_output)\n",
    "        \n",
    "    def params(self):\n",
    "        # Collect parameters and their gradients in a list of tuples\n",
    "        parameters = [\n",
    "            (self.conv1.W, self.conv1.gradW),\n",
    "            (self.conv1.b, self.conv1.gradB),\n",
    "#             (self.conv2.W, self.conv2.gradW),\n",
    "#             (self.conv3.W, self.conv3.gradW),\n",
    "#             (self.conv4.W, self.conv4.gradW),\n",
    "            (self.fc1.W, self.fc1.gradW),\n",
    "            (self.fc1.b, self.fc1.gradB),\n",
    "            (self.fc2.W, self.fc2.gradW),\n",
    "            (self.fc2.b, self.fc2.gradB),\n",
    "            (self.fc3.W, self.fc3.gradW),\n",
    "            (self.fc3.b, self.fc3.gradB)\n",
    "        ]\n",
    "        return parameters\n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8dda7895",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:01.462450Z",
     "start_time": "2023-11-15T15:09:01.453039Z"
    }
   },
   "outputs": [],
   "source": [
    "model = SimpleCNN(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "186a362a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:01.465274Z",
     "start_time": "2023-11-15T15:09:01.463416Z"
    }
   },
   "outputs": [],
   "source": [
    "class SGD:    \n",
    "    @classmethod\n",
    "    def step(cls, parameters, lr):\n",
    "        for param, grad in parameters:\n",
    "            param -= lr * grad  # Update using gradient and learning rate\n",
    "            \n",
    "    @classmethod\n",
    "    def zero_grad(cls, parameters):\n",
    "        for param, grad in parameters:\n",
    "            grad.fill(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "61e04c35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:01.468385Z",
     "start_time": "2023-11-15T15:09:01.466191Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "35f9b169",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:01.471370Z",
     "start_time": "2023-11-15T15:09:01.469092Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = SGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dccc7c35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:01.474605Z",
     "start_time": "2023-11-15T15:09:01.472090Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = dataloader.num_samples\n",
    "    num_batches =(len(dataloader) + CFG.batch - 1) // CFG.batch\n",
    "    \n",
    "    train_loss, correct = 0, 0\n",
    "    \n",
    "    for b, (X, y) in enumerate(dataloader):\n",
    "        y = y.astype(int)\n",
    "        # Convert target labels to one-hot encoding\n",
    "        y_one_hot = np.eye(CFG.num_classes)[y]\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y_one_hot)\n",
    "        grad = loss_fn.backward()\n",
    "        \n",
    "        model.backward(grad)\n",
    "        # Update weights\n",
    "        optimizer.step(model.params(), CFG.learning_rate)  # To update parameters\n",
    "        optimizer.zero_grad(model.params())  # To reset gradients to zero\n",
    "        train_loss += loss.item()\n",
    "        correct += (pred.argmax(1) == y).sum()       \n",
    "    train_loss /= num_batches\n",
    "    accuracy = (100 * correct) / size\n",
    "    print(f\"Train error:\\n Accuracy: {accuracy:.1f}%  Avg loss: {train_loss:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f84b3a8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:09:01.478245Z",
     "start_time": "2023-11-15T15:09:01.475290Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    test_loss, correct, total = 0, 0, 0\n",
    "    \n",
    "    for b, (X, y) in enumerate(testloader):\n",
    "        y = y.astype(int)\n",
    "        y = np.eye(CFG.num_classes)[y]\n",
    "        pred = model(X)\n",
    "        test_loss += loss_fn(pred, y)\n",
    "        total += len(y)\n",
    "        correct += (pred.argmax(1) == y.argmax(1)).sum()\n",
    "    loss = test_loss / b\n",
    "    correct = 100.*correct/total\n",
    "    print(f\"Test Error:\\n Accuracy: {(correct):>.1f}%, Avg loss: {(loss):>.8f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9484c202",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:27:02.427253Z",
     "start_time": "2023-11-15T15:09:01.478953Z"
    },
    "hide_input": false,
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Train error:\n",
      " Accuracy: 11.2%  Avg loss: 183.25807262\n",
      "Test Error:\n",
      " Accuracy: 12.8%, Avg loss: 2.34217186\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train error:\n",
      " Accuracy: 14.5%  Avg loss: 180.64410242\n",
      "Test Error:\n",
      " Accuracy: 15.2%, Avg loss: 2.31865685\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train error:\n",
      " Accuracy: 16.9%  Avg loss: 178.76799157\n",
      "Test Error:\n",
      " Accuracy: 18.2%, Avg loss: 2.28776806\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train error:\n",
      " Accuracy: 20.3%  Avg loss: 176.08172183\n",
      "Test Error:\n",
      " Accuracy: 21.3%, Avg loss: 2.25751534\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train error:\n",
      " Accuracy: 23.2%  Avg loss: 173.80987893\n",
      "Test Error:\n",
      " Accuracy: 23.8%, Avg loss: 2.23211205\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train error:\n",
      " Accuracy: 25.6%  Avg loss: 171.99751100\n",
      "Test Error:\n",
      " Accuracy: 26.0%, Avg loss: 2.20956715\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train error:\n",
      " Accuracy: 27.7%  Avg loss: 170.33000627\n",
      "Test Error:\n",
      " Accuracy: 28.5%, Avg loss: 2.18504008\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train error:\n",
      " Accuracy: 30.3%  Avg loss: 168.29820532\n",
      "Test Error:\n",
      " Accuracy: 31.1%, Avg loss: 2.15846433\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train error:\n",
      " Accuracy: 31.8%  Avg loss: 167.09985539\n",
      "Test Error:\n",
      " Accuracy: 32.6%, Avg loss: 2.14326314\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train error:\n",
      " Accuracy: 33.5%  Avg loss: 165.79555100\n",
      "Test Error:\n",
      " Accuracy: 34.0%, Avg loss: 2.12975846\n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train error:\n",
      " Accuracy: 34.7%  Avg loss: 164.85973574\n",
      "Test Error:\n",
      " Accuracy: 35.0%, Avg loss: 2.11962914\n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train error:\n",
      " Accuracy: 35.6%  Avg loss: 164.12278445\n",
      "Test Error:\n",
      " Accuracy: 35.7%, Avg loss: 2.11196905\n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train error:\n",
      " Accuracy: 36.5%  Avg loss: 163.42682379\n",
      "Test Error:\n",
      " Accuracy: 36.5%, Avg loss: 2.10429507\n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train error:\n",
      " Accuracy: 37.2%  Avg loss: 162.87311075\n",
      "Test Error:\n",
      " Accuracy: 37.1%, Avg loss: 2.09819489\n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train error:\n",
      " Accuracy: 38.0%  Avg loss: 162.27079071\n",
      "Test Error:\n",
      " Accuracy: 37.7%, Avg loss: 2.09154522\n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train error:\n",
      " Accuracy: 38.7%  Avg loss: 161.66918558\n",
      "Test Error:\n",
      " Accuracy: 38.3%, Avg loss: 2.08561433\n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train error:\n",
      " Accuracy: 39.4%  Avg loss: 161.15938146\n",
      "Test Error:\n",
      " Accuracy: 38.9%, Avg loss: 2.08014211\n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train error:\n",
      " Accuracy: 39.8%  Avg loss: 160.81672548\n",
      "Test Error:\n",
      " Accuracy: 39.4%, Avg loss: 2.07459055\n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train error:\n",
      " Accuracy: 40.2%  Avg loss: 160.45214509\n",
      "Test Error:\n",
      " Accuracy: 39.8%, Avg loss: 2.07000929\n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train error:\n",
      " Accuracy: 40.8%  Avg loss: 160.04590031\n",
      "Test Error:\n",
      " Accuracy: 40.2%, Avg loss: 2.06615812\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in range(CFG.epoch):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(trainloader,model, loss_fn, optimizer)\n",
    "\n",
    "    test(testloader, model, loss_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d99e537f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:27:23.684730Z",
     "start_time": "2023-11-15T15:27:02.428484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error:\n",
      " Accuracy: 40.8%  Avg loss: 159.81231409\n"
     ]
    }
   ],
   "source": [
    "size = trainloader.num_samples\n",
    "num_batches =(len(trainloader) + CFG.batch - 1) // CFG.batch\n",
    "\n",
    "train_loss, correct = 0, 0\n",
    "\n",
    "for b, (X, y) in enumerate(trainloader):\n",
    "    y = y.astype(int)\n",
    "    # Convert target labels to one-hot encoding\n",
    "    y_one_hot = np.eye(CFG.num_classes)[y]\n",
    "    pred = model(X)\n",
    "    pred = pred.astype(np.int64)\n",
    "    loss = loss_fn(pred, y_one_hot)\n",
    "    grad = loss_fn.backward()\n",
    "    \n",
    "    model.backward(grad)\n",
    "    # Update weights\n",
    "    optimizer.step(model.params(), CFG.learning_rate)  # To update parameters\n",
    "    optimizer.zero_grad(model.params())  # To reset gradients to zero\n",
    "    train_loss += loss.item()\n",
    "    correct += (pred.argmax(1) == y).sum()       \n",
    "train_loss /= num_batches\n",
    "accuracy = (100 * correct) / size\n",
    "print(f\"Train error:\\n Accuracy: {accuracy:.1f}%  Avg loss: {train_loss:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6847be3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:27:23.687934Z",
     "start_time": "2023-11-15T15:27:23.685586Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f4aff05d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:27:23.692490Z",
     "start_time": "2023-11-15T15:27:23.688626Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 4, 2, 0, 6, 9, 3, 5, 5, 2, 0, 7, 7, 5, 7, 5, 3, 4, 1, 4, 3, 1,\n",
       "       0, 7, 7, 3, 6, 4, 1, 0, 0, 9, 2, 2, 7, 2, 0, 5, 9, 0, 3, 5, 1, 8,\n",
       "       0, 2, 3, 9, 5, 3, 9, 1, 0, 3, 9, 5, 5, 2, 6, 7, 6, 1, 7, 2, 2, 8,\n",
       "       6, 6, 8, 6, 0, 4, 3, 3, 8, 8, 5, 8, 2, 4, 9, 7, 8, 1, 3, 8, 6, 8,\n",
       "       4, 0, 9, 0, 0, 3, 8, 5, 9, 2, 9, 9, 0, 4, 2, 5, 9, 4, 6, 6, 1, 1,\n",
       "       8, 1, 8, 8, 9, 6, 0, 5, 4, 1, 7, 4, 7, 1, 5, 3, 9, 7])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e0777c12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:27:23.712083Z",
     "start_time": "2023-11-15T15:27:23.693301Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f054258a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:27:56.821231Z",
     "start_time": "2023-11-15T15:27:23.713346Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error:\n",
      " Accuracy: 40.6%, Avg loss: 2.06234686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss, correct, total = 0, 0, 0\n",
    "    \n",
    "for b, (X, y) in enumerate(testloader):\n",
    "    y = y.astype(int)\n",
    "    y = np.eye(CFG.num_classes)[y]\n",
    "    pred = model(X)\n",
    "    test_loss += loss_fn(pred, y)\n",
    "    total += len(y)\n",
    "    correct += (pred.argmax(1) == y.argmax(1)).sum()\n",
    "loss = test_loss / b\n",
    "correct = 100.*correct/total\n",
    "print(f\"Test Error:\\n Accuracy: {(correct):>.1f}%, Avg loss: {(loss):>.8f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
